---
title: Imaging
bibliography: Top-10-FAIR-imaging.bib
link-citations: yes
---

## Top 10 FAIR for imaging

### Authors
*   Paula Andrea Martinez [https://orcid.org/0000-0002-8990-1985](https://orcid.org/0000-0002-8990-1985) - [National Image Facility (NIF)](http://anif.org.au/) and [Characterisation Virtual Laboratory (CVL)](http://cvl.org.au/)
*   Gerry Ryder [https://orcid.org/0000-0001-7444-4489](https://orcid.org/0000-0001-7444-4489) - [Australian Research Data Commons (ARDC)](https://ardc.edu.au/)
*   Aswin Narayanan [https://orcid.org/0000-0002-4473-7886](https://orcid.org/0000-0002-4473-7886) - [National Image Facility](http://anif.org.au/)
*   Iryna Kuchma [https://orcid.org/0000-0002-2064-3439](https://orcid.org/0000-0002-2064-3439) - [FOSTER](https://www.fosteropenscience.eu/) and [OpenAIRE](https://www.openaire.eu/)
*   Jose Manzano Patron - University of Nottingham
*   Andrew Mehnert - Centre for Microscopy Characterisation and Analysis and The University of Western Australia


### Description:
This guide aims to promote the FAIR data principles and to encourage their adoption by the bioimaging and [characterisation](#characterisation) community. The FAIR principles are described in the context of bioimaging  and characterisation and the activities are optional. This guide seeks to empower researchers, scientists and health professionals to enable them to adopt best data practices throughout the research lifecycle, to improve the quality, reproducibility and reusability of research outputs.

### Audience:
Researchers, neuroscientists, clinicians, microscopists, platform engineers, graduate students and computational and data scientists working on image analysis and processing.

### Goals:
To inform data producers and users about the FAIR principles applied to bioimaging/characterisation and suggest activities to apply to their research.

## Table of Contents:

[1. What is FAIR?](#1-what-is-fair?)
[2. What are publishers and funders saying about data access?](#2-what-are-publishers-and-funders-saying-about-data-access)
[3. Data sharing and discovery](#3-data-sharing-and-discovery)
[4. Reusable data repositories for the image community](#4-reusable-data-repositories-for-the-image-community)
[5. Managing and sharing sensitive data](#5-managing-and-sharing-sensitive-data)
[6. Persistent identifiers](#6-persistent-identifiers)
[7. Describing data: metadata](#7-describing-data-metadata)
[8. Reusable data best practices](#8-reusable-data-best-practices)
[9. Licensing your work](#9-licensing-your-work)
[10. Data citation for access and attribution](#10-data-citation-for-access-and-attribution)
[Supplementary Information](#supplementary-information)
[References](#references)


## **_1. What is FAIR?_**

The acronym FAIR, as detailed in [15 principles](https://www.go-fair.org/fair-principles/) [@go_fair_fair_2016] stands for *Findable*, *Accessible*, *Interoperable* and *Reusable*. The [FAIR principles](http://www.nature.com/articles/sdata201618) [@wilkinson_fair_2016] are guidelines to motivate and enhance *reusability* of data, by facilitating its *discovery*, *integration* and *evaluation*. In this context, "data" refers to all research-oriented digital objects (including data, metadata, software, workflows and packages) [@wilkinson_interoperability_2017]. Wilkinson et al., pioneered the definition of the guiding principles "emphasising the capacity of computational systems to Find, Access, Interoperate and Reuse data with none or minimal human intervention", this is referred to machine-actionable FAIR principles. FAIR is also connected with research data management and open science, as [@higman_three_2019] describe.

> **“FAIRness is a prerequisite for proper data management and data stewardship”**

Communities are motivated to apply the FAIR principles to research activities and to enable people and machines to find, read, use and reuse research data and research outputs. For instance, in 2018, [@copdess_enabling_2018], a coalition of stakeholders representing the international Earth and Space science community set out to develop standards to connect researchers, publishers, and data repositories in this community to enable FAIR data on a large scale. This project will accelerate scientific discovery and enhance the integrity, transparency, and reproducibility of this data. In imaging, on 1 March 2019, [@bioimaging_eosc-life] and other research infrastructures including [ELIXIR-Europe](https://elixir-europe.org/) joined forces as part of the The [European Open Science Cloud](https://www.eosc-hub.eu/) project to publish research data via FAIR databases. Community participation from academia, industry, small and medium-sized enterprises (SMEs) and regional bio-clusters is paramount for the success of this four-year project (starting in 2020). The imminent global uptake of the FAIR principles in different scientific domains, serves to motivate the bioimaging/characterisation community to do likewise and to move forward, promote and apply them.

Activity 1: In 2018, CODATA, The Committee on Data for Science and Technology, [@codata_enabling_2018] “Enabling FAIR Data Project and Commitment Statement”. Take a look at the partners in [@copdess_enabling_2018], do you recognise partners in your discipline?

Activity 2: Can you think of the benefits of making your data FAIR? How can you align your current data practices to the FAIR principles? Consider the following resources when addressing the activity above:

* "How to make your data FAIR" by the Australian Research Data Commons (ARDC) [@ands_fair_2017].
* "The Research Data Lifecycle - A Model for Data Management" by [@alan_turing_institute_research_2019], or the Curation Lifecycle Model by [@dcc_lc_nodate].
* "What is FAIR data? by LIBER (Europe’s Research Library Network) [@cavalli_open_2018].
* "Interpretation of the FAIR data principles by the Swiss National Science Foundation (SNSF) [@swiss_national_science_foundation_explanation_2018].


## **_2. What are publishers and funders saying about data access?_**

The following examples and statements are meant to motivate organisations and researchers to adopt the next steps towards FAIR. As disclaimer, most of the examples are from Australian stakeholders as the guide is being developed in Australia; nonetheless, international examples have also been included.

“Nature journals require sharing research materials because their core business is ensuring research quality and promoting research to the widest readership” ([Nature Genetics, 2004](https://www.nature.com/articles/ng1004-1025)) [14].

In 2014, The Nature Publishing Group welcomed its newest journal, [_Scientific Data_](https://www.nature.com/sdata/) [15] — a peer-reviewed, open-access publication designed to provide a better way to share and explain data. _Scientific Data_ [promotes reproducible, collaborative science and due credit to scientists](https://www.nature.com/articles/nphys3033) [16].

PLOS journals require authors [to make all data underlying the findings described in their manuscript fully available without restriction at the time of publication](https://journals.plos.org/plosone/s/data-availability#loc-acceptable-data-sharing-methods) [17]. PLOS suggests using [FAIRsharing](https://fairsharing.org/) [18] to index resources, for example their own [PLOS list of recommended resources](https://fairsharing.org/recommendation/PLOS) [19].

[eLife Journal Policy](https://submit.elifesciences.org/html/elife_author_instructions.html#policies) [20] "wherever possible, authors should make major datasets available using domain-specific public archives, or generic databases, e.g. [FAIRsharing page for eLife recommended repositories and standards](https://fairsharing.org/recommendation/eLifeRecommendedRepositoriesandStandards)" [21].

Funders like the European Commission have drafted [Guidelines on FAIR Data Management for the H2020 programme](http://ec.europa.eu/research/participants/data/ref/h2020/grants_manual/hi/oa_pilot/h2020-hi-oa-data-mgt_en.pdf) (European Commission, 2016) "those projects funded in this scheme must submit a version of this FAIR Data Management Plan (DMP)" [25].

The Australian [2016 National Research Infrastructure Roadmap](https://docs.education.gov.au/system/files/doc/other/ed16-0269_national_research_infrastructure_roadmap_report_internals_acc.pdf) [26] has two FAIR highlights: 1. Australia must stay at the forefront of international developments and should continue to engage with internationally recognised initiatives… such as the FAIR guiding principles. 2.The Australian National Data Service (ANDS) (now ARDC) has been a foundational, providing in many cases leading, international policies and practices to support researchers and institutions in making data FAIR.

In 2016, The European Commission General directorate for Research and Innovation published the report and action plan [Turning FAIR into reality](https://ec.europa.eu/info/sites/info/files/turning_fair_into_reality_1.pdf) [27] to implement FAIR and provide concrete recommendations and actions for stakeholders in Europe and beyond.

Starting in September 2016, all research papers accepted for publication in _Nature_ and an initial 12 other Nature Research titles will be required to include information on whether and how others can access the underlying data. [Nature Announcement: where are the data?](http://www.nature.com/news/announcement-where-are-the-data-1.20541).

The Australian Research Council [(ARC) Open Access Policy Version 2017.1](https://www.arc.gov.au/policies-strategies/policy/arc-open-access-policy-version-20171) [28] states "Author(s) should consider selecting publishers and research outlets, which have policies supporting the F.A.I.R. principles, as well as immediate or early availability of Publications via Open Access, in order to maximise the availability and impact of their ARC Funded Research."

Policy Statement (2017) On FAIR Access To Australia's Research Outputs [https://www.fair-access.net.au/fair-statement](https://www.fair-access.net.au/fair-statement) [29] Headline: By 2020, Australian publicly funded researchers and research organisations will have in place policies, standards and practices to make publicly funded research outputs findable, accessible, interoperable and reusable to the Australian and international community.

The (Australian) National Health and Medical Research Council (NHMRC) promotes the highest quality in the research that it funds, based on international best practice. The [NHMRC lists the FAIR principles under useful resources](https://www.nhmrc.gov.au/research-quality) [30] for publication and reporting of research outcomes.

In late 2017, Australian Health Research Alliance (AHRA) committed to developing a coordinated national approach to Data Driven Healthcare Improvement. [Leveraging data registration, linkage, integration, storage, security, access, management and analysis capabilities](https://www.wahtn.org/wp-content/uploads/2019/05/Data-Driven-Healthcare-Improvement.pdf) [31].

In 2018, [The Enabling FAIR Data Commitment Statement](http://www.copdess.org/enabling-fair-data-project/commitment-to-enabling-fair-data-in-the-earth-space-and-environmental-sciences/) [32], has been formalised, by a significant group of stakeholders (repositories, publishers, societies, communities, institutions, funding agencies and organisations, and researchers) to support and promulgate open and FAIR data principles and practices in their core science activities and policies.

Wiley’s data sharing and citation policies and service support the growing movement to make [research more open](https://authorservices.wiley.com/open-research/index.html) [34], because this leads to a fairer, more efficient and accountable research landscape, driving effective and faster pace of discovery [Wiley's Data sharing and citation](https://authorservices.wiley.com/author-resources/Journal-Authors/open-access/data-sharing-citation/index.html) [35].

[The Genomics Health Futures Mission (GHFM)](https://www.business.gov.au/assistance/genomics-health-futures-mission-projects) - [Projects Grant Opportunity guidelines 2019 states](https://www.business.gov.au/-/media/Business/ghfmpg/Genomics-Health-Futures-Mission-Projects-Grant-Opportunity-guidelines-PDF.pdf) “research projects proposals with plans to manage genomic and/or phenomic data in alignment with the FAIR principles for research data are preferred”.

All disciplines should follow the geosciences and demand best practice for publishing and sharing data” ([Stall et al., 2019](https://www.nature.com/articles/d41586-019-01720-7)) [23].

“Grant makers, professional organisations, research journals, publishers, and other entities in the research field increasingly stress the ethics as well as societal and practical benefits of data sharing, and require researchers to do so within a reasonable time after data collection ends.” ([Dijkers, 2019](https://doi.org/10.1038/s41393-018-0232-6)) [24].

## **_3. Data sharing and discovery_**

_Why sharing?_

“Both researchers and the broader community stand to benefit from the knowledge produced through publicly funded research” [@council_arc_2018]. Data sharing is well connected with the concept of reproducibility.

“Data created and used by scientists should be managed, curated, and archived in such a way to preserve the initial investment in collecting them. Researchers must be certain that data held in archives remain useful and meaningful into the future. Funding authorities increasingly require continued access to data produced by the projects they fund, and have made this an important element in Data Management Plans. Indeed, some funders now stipulate that the data they fund must be deposited in a trustworthy repository.” [@cts_introduction_2016].

Activity 1: (Infographic) Research data may be discovered (_findable_) and shared (_accessible_) in many ways. Start by looking at some data sharing trends [@wiley_researcher_2014] across countries and research disciplines. Consider your own current data sharing practices, and those of your project team(s). How FAIR are they?

Activity 2: How can data be shared and discovered? Think about open, mediated, restricted access data repositories. What examples of these types of repositories are you aware of? Discuss with others about their answers.


## **_4. Reusable data repositories for the image community_**

_How to walk towards FAIR?_

Imagine if you were able to obtain extra datasets for your existing research project, or start a new project reusing publicly available datasets. You can do this by exploring the following reusable data repositories for the imaging community, divided by topic.

**[Reusable data repositories](#1-Reusable-data-repositories-section-4)**
1. **[Neurosciences](#neurosciences)**
1. **[Microscopy](#microscopy)**
1. **[Biomedical sciences](#biomedical-sciences)**
1. **[Non-domain specific data registries and catalogues](#non-domain-specific)**

This and the previous section intend to show that it is becoming more common for funding agents and publishers to require research data to be made _accessible_ via appropriate repositories. This list is a starting point for you to _find_ out what data already exists in your research area. If you want to share your data, or find data relevant to your research take a detailed look at the examples provided, most if not, all will have guides on how to share data.

Activity 1: Find repositories for imaging in [FAIRsharing.org](https://fairsharing.org/biodbcore/?q=imaging) and search for repositories relevant to your research. Try for example, searching on "neuroimaging". Explore at least one repository you find. How well does it support the FAIR data principles? Tip: look for things such as persistent identifiers, clear descriptions, licence information, download options, file formats.


## **_5. Managing and sharing sensitive data_**

Clarification, FAIR data is not necessarily “open” data. There are some good reasons why some data should not be open. For example, to protect intellectual property, commercialisation, national security, personal privacy or endangered species. However, it may still be possible to provide mediated _access_ to such data, or to publish a description of the data so that others can _discover_ its existence. To align with FAIR principles your “_research data should be as open as possible, as closed as necessary_”.

The FAIR principles encourage us to disseminate data as widely as possible, in the most effective manner and at the earliest opportunity. This statement takes into account any restrictions relating to privacy, confidentiality, intellectual property, embargo period, or cultural sensitivities, that need to be addressed, discussed and clarified before sharing any data. In the planning phase of a research project, researchers need to consider at least making project metadata publicly accessible.

If you need examples and more information, check OpenAIRE sensitive data guide [@openaire_how_2017], ANDS publishing and sharing sensitive data [ands_publishing_nodate], Earth Science Information Partners (ESPI) Handling sensitive data tutorial [@downs_providing_2012]. In addition, The Australian Bureau of Statistics (ABS) informs of the five safes framework [@cw_managing_2017] and Table 2 provides examples at different levels of accessibility.

Activity 1: Promoting FAIR principles in the healthcare field [@dcc_promoting_2019]. Highlights: The sensitive nature of patient data and additional concerns for these data include security and anonymisation of data subjects as major components considered. For more information visit [FAIR4health.eu](https://www.fair4health.eu/).

Activity 2: Think about when and how people can share data along the research cycle. Keeping in mind that it is strongly recommended to release metadata (description) of the project to comply with FAIR principles, even if you cannot share the data itself. Institutional repositories or domain specific repository should be able to store metadata of your project and then link that information via registries (Look the previous section).

**De-identification / Anonymisation**

In the case of sensitive data, the aim is to _minimise the risk of exposing confidential information_. Sometimes restrictions on sharing can be resolved by de-identification or anonymisation of data. Anonymisation is sometimes used interchangeably with de-identification, ANDS makes a clarification of these terms[@ands_-identification_2018].

* De-identification is the removal of identifying information from a dataset, and this data could potentially be re-identified e.g. if the identifying information is kept (as a key) and recombined with the de-identified dataset.
* Anonymisation is the permanent removal of identifying information, with no retention of the identifying information separately.

Activity 3: Look at The Future of Privacy Forum’s visual guide to practical data de-identification [@future_of_privacy_forum_visual_2017].

Optional extra information. 1. Open de-identification tools from Open Brain Consent [@halchenko_anonymization_2018]. 2. The (Health Insurance Portability and Accountability Act) HIPAA Privacy Rule establishes national standards (US) to protect individuals' medical records and personal health information [@sweeney_identifiability_nodate], and guidance about methods for de-identification [@health_information_privacy_methods_2012]. 3 Anonymization of DICOM Electronic Medical Records [@newhauser_anonymization_2014].

## **_6. Persistent identifiers_**

Identifiers are essential to the human-machine interoperation. Assigning globally unique persistent identifiers “is arguably the most important FAIR principle, because it will be hard to achieve other aspects of FAIR without them” ([F1](https://www.go-fair.org/fair-principles/f1-meta-data-assigned-globally-unique-persistent-identifiers/)). Persistent identifiers or PIDs help find and collect data accurately, enable proper citation by collecting citation _metrics_ about the use of a dataset, article or data generator (e.g. instrument, software, workflow). For the researcher, persistent identifiers enable disambiguation of people and enable linking existing works.

**For individuals:**
*   [ORCID](https://orcid.org/content/orcid-overview-researchers) Open Researcher and Contributor ID is a persistent digital identifier for an individual researcher. Activity: [Why an ORCID? By WILEY](https://authorservices.wiley.com/author-resources/Journal-Authors/submission-peer-review/orcid.html)
*   [A Web of Science ResearcherID](https://clarivate.com/products/Web+of+Science+ResearcherID) is a unique identifier that connects researchers with works across the Web of Science ecosystem (_Web of Science_, _Publons_, and _InCites_).

**For digital objects (files, datasets, publications, software, etc.):**
*   DOI stands for Digital Object Identifier, which is a unique persistent identifier for a published digital object, issued by the DOI Foundation and its registered agencies [using the handle system](https://www.doi.org/factsheets/DOIHandle.html).
*   RAiD Research Activity Identifier ([RAiD](https://www.raid.org.au/)) for research activities and projects Persistent Uniform Resource Locator (PURL) currently in the process of becoming a universal PID.

Disclaimer, there are a wide range of PIDs available, we only cited two examples for each type.

Activity 1: [OpenAIRE](https://www.openaire.eu)/[FREYA](https://www.project-freya.eu/en)/[ORCID](https://orcid.org) guide for researchers [“How can identifiers improve the dissemination of your research outputs?”](https://www.openaire.eu/how-can-identifiers-improve-the-dissemination-of-your-research-outputs)

Activity 2: [Six Ways to Make Your ORCID iD Work for You!](https://orcid.org/blog/2018/07/27/six-ways-make-your-orcid-id-work-you) If you already have an ORCID, check this [video](https://www.youtube.com/watch?v=h92bUZ5T_vA) to link publications to your ORCID profile.

Activity 3: (Discuss in pairs, 5 min) [The Joint Declaration of Data Citation Principles from FORCE11](https://doi.org/10.25490/a97f-egyk) [https://www.force11.org/datacitationprinciples](https://www.force11.org/datacitationprinciples)

To learn more about persistent identifiers visit Go-FAIR [F1 Principle](https://www.go-fair.org/fair-principles/f1-meta-data-assigned-globally-unique-persistent-identifiers/) or the [ARDC identifiers examples](https://ardc.edu.au/resources/working-with-data/citation-identifiers/).

## **_7. Describing data: metadata_**

“Metadata (information about data) provides means for discovering data objects as well as providing other useful information about the data objects such as experimental parameters, creation conditions, etc.” ([Rajasekar & Moore, 2001](https://doi.org/10.1007/3-540-48228-8_8)).

Why is building and using metadata relevant? Because it supports the discovery, understanding and organisation of the process of research data across different communities, [more information](http://www.dcc.ac.uk/resources/curation-reference-manual/completed-chapters/metadata).

Some aspects of metadata to keep in mind whether you produce, read or reuse metadata. Creating, using and reusing metadata emphasises the need for a standard vocabulary, in order to properly be interpreted by either humans or software. Hence, why metadata items need to be precisely defined. A defined list of agreed terms constitutes a controlled vocabulary, which is usually led by a user-community. Controlled vocabularies help data integration when, for example, ambiguities may exist on the terms used in the different datasets and across different repositories. If the data are to be re-used outside this community additional information may be required.

Controlled vocabularies are part of a model called an ontology. An ontology has controlled vocabularies and the glue to link the terms providing an effective means whereby human and electronic agents can communicate unambiguously about concepts. This is relevant to the *Interoperability* principle of FAIR [I1](https://www.go-fair.org/fair-principles/i1-metadata-use-formal-accessible-shared-broadly-applicable-language-knowledge-representation/). The goal of making data interoperable is to enable members of disparate communities to reuse and understand digital information over time.

Metadata for imaging should include a standard terminology and tools for describing physiological, clinical, demographic and genetic changes. The main recommendation is to share metadata per project whenever possible, even if the data is not yet available. Remember that metadata can be stored in general purpose repositories.

We can group metadata types in two: either automatically created metadata or manually created metadata, [more information](https://ardc.edu.au/resources/working-with-data/metadata/).

**a. Why ontologies?**

By expressing image/characterisation annotation in machine computable form as a formal ontology, human knowledge can be brought to bear on effective search and interpretation of image data, especially across multiple disciplines, scales, and modalities” ([Eliceiri et al. 2012](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3659807/#BX3)). Keep in mind that if privacy is an issue, any (meta)data can be listed under embargo.

Implementation, adoption and harvesting of metadata, requires defined ontologies. Due to increased demand for quantitative analysis and robust curation and sharing of the image/ characterisation data, the need for full ontologies and annotations is growing.

More examples, Ontologies for Neuroscience describe three domain specific ontologies and how they build on top of each other [Larson & Martone, 2009](https://doi.org/10.3389/neuro.01.007.2009). They also note that existing domain specific vocabularies built the ontology with the help of the [Open Biological Ontologies (OBO)](http://obofoundry.org/) ([Smith et al., 2007](https://doi.org/10.1038/nbt1346)) community. For example a subset of OBO is the [EDAM Ontology](https://bioportal.bioontology.org/ontologies/EDAM-BIOIMAGING) for bio-imaging ([Kalaš et al., 2019](https://doi.org/10.5281/zenodo.2557012)). The Neuroscience Information Framework has developed a comprehensive vocabulary [NIF Standard ontology (NIFSTD)](http://bioportal.bioontology.org/ontologies/40510) for annotating and searching neuroscience resources. [Plant et al., 2011](https://doi.org/10.1186/1471-2105-12-487) provide an overview of what is needed to implement metadata that follows domain specific ontologies, they use as example microscopy cell image data. The [National Center for Biomedical Ontology (NCBO)](https://www.bioontology.org/) NCBO's [BioPortal](https://bioportal.bioontology.org/ontologies) provides access to more than 270 biomedical ontologies and controlled terminologies ([Musen et al., 2012](https://doi.org/10.1136/amiajnl-2011-000523)), and include some of those cited before. The Ontology for Biomedical Investigations ([Bandrowski et al., 2016](https://doi.org/10.1371/journal.pone.0154556)), [OBI Ontology.org](http://obi-ontology.org/) enables communication between existing ontologies.

**b. Controlled vocabularies**

Domain specific controlled vocabularies might be a wider landscape than ontologies to cover here, hence some more generic vocabulary examples are given. [Schema.org](http://schema.org) widely used to build controlled vocabularies, a more specific example is [bioschemas.org](https://bioschemas.org/specifications/Dataset/) a collection of specifications that provide guidelines to facilitate a more consistent adoption of [schema.org](https://schema.org/) within the life sciences. [Research vocabularies Australia](https://vocabs.ands.org.au/) is a public database of controlled vocabularies, at the time of writing this guide, [no specific bioimaging vocabularies were found](https://vocabs.ands.org.au/vocabs/page/widget_explorer), maybe that is something you can help with?

**c. Storing and publishing metadata**

Where to store and publish metadata? The short answer is, depends which institution you are from. Enquiring the library, research officer or data steward are the best sources of information. Some options are:

1. Institutional repositories
2. Domain specific repositories
3. Generic repositories

Keep in mind that the FAIR principle [A2. Metadata are accessible, even when the data are no longer available](https://www.go-fair.org/fair-principles/a2-metadata-accessible-even-data-no-longer-available/), which reinforces the need of having at least shared metadata. For example, first look at the section "Reusable data repositories for the image community". For a broad view [FAIRsharing.org databases for imaging](https://fairsharing.org/biodbcore/?q=imaging). The ARDC - Research Data Archive ([RDA](https://researchdata.ands.org.au/)) harvests institutional repositories, hence it can be a generic repository. [The CSIRO - data access portal](https://data.csiro.au/collections/) (for projects related to CSIRO). [DataCite metadata store](https://support.datacite.org/docs/mds-api-guide) allows users to register DataCite DOIs and associated metadata. [Zenodo](https://zenodo.org), provides a DOI and versioning capabilities.

Activity 1: (Discuss in pairs) Have a look at the metadata stored at Research Data Australia for the [7T Magnetom](https://researchdata.ands.org.au/7t-magnetom/1305790) instrument. It contains simple but important public metadata and a PID.
Activity 2: [Where to store metadata](https://www.ands.org.au/working-with-data/metadata/storing-metadata)? from ARDC.

## **_8. Reusable data best practices_**

Here is a suggested list of data best practices to adopt in your research outputs. These will improve data and software reusability by others, which includes yourself in the future. Remember, making data/software available for others to re-use publicly is the goal, but not all data must be shared to all. Adding terms and conditions of accessibility is an option to consider. To share data, you can make use of public infrastructures already mentioned (section "4. Reusable data repositories") or use your institutionally provided data repository. To get started, there are a few things you should keep in mind.

**a. Provenance** - Usually provenance is a manually produce metadata file (it can also be automatically produced). It is important for the reuse of data in the future, it should contain descriptors such as data producer, date history (log of changes), data dictionary. **Primary data ought to be read only.**

**b. File formats** - Most file formats are defined by the data producer (e.g. instrument or software), whenever possible you should try to convert data to formats that are publicly accessible.

[DICOM](https://fairsharing.org/FAIRsharing.b7z8by) Digital Imaging and Communications in Medicine. Mostly used in neurosciences, can be converted to [NIfTI](https://fairsharing.org/FAIRsharing.jgzts3)(Neuroimaging Informatics Technology Initiative) or [BIDS format](https://neurostars.org/t/convert-data-to-bids-format/720). [Bio-formats](https://docs.openmicroscopy.org/bio-formats/6.1.0/about/index.html). The Hierarchical Data Format version 5 (HDF5), is an open source file format that supports large, complex, heterogeneous data [HDF5](https://dx.doi.org/10.1145%2F1562764.1562781)) used by [MINC]([https://bic-mni.github.io/](https://bic-mni.github.io/)) and [Huygens Software](https://svi.nl/HuygensSoftware). Tiff, extensively used in Microscopy.

**c. Data structures** Keep consistent file and folder naming conventions across linked projects.
* Brain imaging data structure (BIDS) [BIDS website](http://bids.neuroimaging.io/), [publication](https://doi.org/10.1038/sdata.2016.44), [fairsharing ID](https://fairsharing.org/FAIRsharing.rd1j6t).
* [IDR metadata example](https://github.com/IDR/idr-metadata).
* [Datacrate example](https://github.com/UTS-eResearch/datacrate).

**d. Data curation** Should be included in your data quality workflow as part of the process, ideally this will be automated.

**e. Data versioning** To keep the provenance of your data you might use data versioning tools: Git or GitHub (for code), [Git annex](https://git-annex.branchable.com/), [Datalad](https://www.datalad.org/).

**f. Containerisation** For data processing pipelines. E.g. Singularity, Docker, or use Virtual environments, such as the [Characterisation Virtual Lab](https://www.cvl.org.au/).

**g. Protocols** [Search for imaging protocols publicly shared](https://protocolexchange.researchsquare.com/?journal=protocol-exchange&limit=10&offset=0&status=all&subjectArea=Imaging). For example, [Protocol Exchange](https://protocolexchange.researchsquare.com) from Nature Protocols is an open resource where the community of scientists pool their experimental know-how to help accelerate research.

**h. Create documentation** A README file helps ensure that your data can be correctly interpreted and reanalysed by others. For example, the [DataDryad Readme](https://datadryad.org//pages/readme) is an example of minimum documentation.

**i. Benchmarks or checksums**

Activity 1: [A brain imaging case study](https://doi.org/10.1101/183814) that provides direct evidence of the impact of open sharing on data use and resulting publications over a seven-year period (2010-2017). “We dispel the myth that scientific findings using shared data cannot be published in high-impact journals and demonstrate rapid growth in the publication of such journal articles” ([Milham, M. P. et al., 2018](https://doi.org/10.1038/s41467-018-04976-1)).

Activity 2 (Discussion + Action): What Can You Do?

>*   Contribute your data – Previously published datasets.
>*   Release some or all of the project metadata – your call, as a simple rule, the more the better!
>*   Curate existing datasets to make available in the future - you set the upload schedule.
>*   Contribute your scripts/code
>*   Have discussions with your team members about licensing and sharing.
>*   Create a data management plan.

Activity 3: Go through the questions from the [Horizon2020 guide to create a FAIR Data Management Plan](http://ec.europa.eu/research/participants/data/ref/h2020/grants_manual/hi/oa_pilot/h2020-hi-oa-data-mgt_en.pdf) and see if you can already answer many of them.

Recommended extra reading: [Best Practices in Data Analysis and Sharing in Neuroimaging using MRI](https://doi.org/10.1101/054262), [Ten Simple Rules for Creating a Good Data Management Plan]( https://doi.org/10.1371/journal.pcbi.1004525), [Ten Simple Rules for Reproducible Computational Research]( https://doi.org/10.1371/journal.pcbi.1003285) and [Ten principles for machine-actionable data management plans]( https://doi.org/10.1371/journal.pcbi.1006750), these papers will help you connect all the concepts that you have learned so far.


## **_9. Licensing your work_**

Licensing your work / research outputs to be open access (research output here means data, metadata, code, workflows) allows you as author or contributor to enable reuse and appropriate attribution of the work. If there is no license attached to your work, you are actually stopping anyone to legally reuse it. Did you know that _No license = No permissions?_. Also, if you find research outputs that you want to reuse, you should only reuse it according to their license.

_Be aware that you have the right to choose a license that best suits your purpose. There are multiple different licenses and versions of these, to be applied to data and software. Some licenses are applicable only in certain countries, think of applying an international license. Be aware that the data repository that you use might ask you to accept their “terms and conditions” which affects how you might use or share data, by expanding, modifying or limiting the intended purpose or your own license. You can have multiple licenses, for different purposes or different audiences. Finally, not every part of your work/ research outputs needs to be publicly available or be licensed. The more you share the better._

Activity 1: [What if you don’t choose a license?](https://choosealicense.com/no-permission/), explains and gives you a few reasons to think about licensing your work. If you are interested in reading about [GitHub terms and conditions](https://help.github.com/en/articles/github-terms-of-service#d-user-generated-content) take 5 extra minutes.

Activity 2: (flowcharts as a survey) The ARDC has a guides about licensing for three specific scenarios: a) [Data creator flowchart](https://www.ands.org.au/__data/assets/pdf_file/0006/1525092/Data-Rightsholders-Creators-Flowchart.pdf) b) [Data supplier flowchart ](https://www.ands.org.au/__data/assets/pdf_file/0020/1525106/Data-Suppliers-Flowchart.pdf) and c) [Data users flowchart](https://www.ands.org.au/__data/assets/pdf_file/0004/1525108/Data-Users-Flowchart.pdf). If you want to know more about licensing and [copyright for data reuse visit the ANDS (now joined into ARDC) page](https://www.ands.org.au/working-with-data/publishing-and-reusing-data/licensing-for-reuse).

A few types of licenses: *[Creative Commons (CC)](http://creativecommons.org/)* is, so far, very easy to apply and it is broadly being reused; it is strongly promoted in the United States, however it is an internationally recognised license creator. CC is good for: a) very simple, factual data sets b) data to be used automatically. You should watch out for the version in use, recommended to use version 4 or later. CC has attribution stacking Non Commercial (NC), Shared Alike (SA) and Non derivatives (ND). The NC condition: only to be used with dual licensing. The SA condition reduces interoperability. The ND condition severely restricts reuse. To help you decide, use this [https://creativecommons.org/choose/](https://creativecommons.org/choose/). *[Copyleft](https://www.gnu.org/licenses/copyleft.en.html)* is a general method for making a program (or other work) free ([in the sense of freedom, not “zero price”](https://www.gnu.org/philosophy/free-sw.html)), and requiring all modified and extended versions of the program to be free as well. *[Open Data commons](https://opendatacommons.org/)*, also provides licenses specifically for open data, good for most databases and datasets, e.g. Open Data Commons Open Database Licence (ODC-ODbL) or Open Data Commons attribution license (ODC-By). Licenses specific for software: *[Mozilla Public Licence (MPL)](https://www.mozilla.org/en-US/MPL/)*, *[MIT Licence](https://opensource.org/licenses/MIT)*, *[the GNU General Public Licence (GPL)](https://www.gnu.org/licenses/licenses.en.html)* and [a list of open source licenses by category](https://opensource.org/licenses/category). To help you choose a license for software, look at the descriptions: [https://choosealicense.com/](https://choosealicense.com/). Acknowledgement, most of the cited licenses on this section, were first mentioned by [License Research Data from the Digital Curation Centre](http://www.dcc.ac.uk/resources/how-guides/license-research-data) (DCC).


## **_10. Data citation for access and attribution_**

Citation analysis and citation metrics are important to the academic community, which gives recognition to the researchers and their work. Data citation continues the tradition of acknowledging other people's work and ideas. It also helps make research data more _findable_ and _accessible_. It is now common practice for authors to formally cite the research datasets and associated software that underpin their research findings.

Activity 1: (Video, 12 mins) [Responsible Data Use: Citation and Credit](http://commons.esipfed.org/node/1428).

Activity 2: _How to cite data and software?_ This [example from Dryad](https://datadryad.org/resource/doi:10.5061/dryad.bh78sn5) clearly shows how to cite the dataset that underpins a journal article as well as the article itself. Note that both citations include a Digital Object Identifier (DOI).

Activity 3: [_What to cite and why?_ For data and software from ARDC](https://ardc.edu.au/resources/working-with-data/citation-identifiers/data-citation/) for more information.

# Acknowledgements

We acknowledge Chris Erdmann for reviewing the first version of this document, and Matthias Liffers for useful comments and the editing section two of this document.

# Pre-print

This document is also available via the Open Science Framework as a pre-print and it is citable with the following [DOI 10.17605/OSF.IO/ZKJ4R](https://osf.io/zkj4r/) where versions of it in .docx and .odt have been saved.
In addition to the website of [Top 10 FAIR for Imaging](https://librarycarpentry.org/Top-10-FAIR/2019/06/27/imaging/)

# Supplementary Information

## Characterisation
"Characterisation is the general process of probing and measuring the structures and properties of materials at the micro, nano and atomic scales. It is essential across natural, agricultural, physical, life and biomedical sciences and engineering."

## Reusable data repositories Section 4

Section 4 lists various public repositories which we have collected in the following list.

### Neurosciences

Data repositories [recommended by the Scientific Data Journal](https://www.nature.com/sdata/policies/repositories#neurosci) which accept human-derived data, in addition [NeuroMorpho.org ](http://neuromorpho.org/) and [G-Node](https://web.gin.g-node.org/) also accept data from other organisms. Please note that human-subject data submitted to OpenNeuro must be de-identified, while [Functional Connectomes Project International Neuroimaging Data-Sharing Initiative (FCP/INDI)](http://fcon_1000.projects.nitrc.org/) can handle sensitive patient data.

*   [Neuromorpho.org](http://neuromorpho.org/) is a centrally curated inventory of reconstruction data for the neuroscience community associated with peer-reviewed publications.
*   [G-Node](https://web.gin.g-node.org/) is a modern Research Data Management for Neuroscience with [git-annex](https://git-annex.branchable.com/) version control. Inspired by Github a rebuilt for distributed file synchronization system dealing with files larger than git can currently easily handle.
*   [Datasets from Datalad.org](http://datasets.datalad.org/) have built-in support for metadata extraction and search. It allows to search through a large collection of readily available datasets. It is the master collection for openneuro/openfmri and neurovault.
*   [Openneuro.org](https://openneuro.org/) (formerly openfMRI) a free and open platform for sharing MRI, MEG, EEG, iEEG, and ECoG data. Get access via orcid or google account. Also accessible via [GitHub OpenNeuro Datasets](https://github.com/OpenNeuroDatasets)
*   [Functional Connectomes Project International Neuroimaging Data-Sharing Initiative (FCP/INDI)](http://fcon_1000.projects.nitrc.org/) can handle sensitive patient data! Upon successful registration users have the right to unrestricted usage of the datasets for non-commercial purposes. Current goal: To make the aggregation and sharing of well-phenotyped datasets a cultural norm for the imaging community.
*   [Central XNAT](https://central.xnat.org/) is a database for sharing neuroimaging and related data with select collaborators or the general community. Available repository options: Public, Protected and Private.
*   [Neurovault.org](https://neurovault.org/) is a public online repository for statistical maps, parcellations and atlases of the brain. It is registered in [identifiers.org](https://registry.identifiers.org/registry/neurovault.image).
*   [Brain Map Portal](http://portal.brain-map.org/) This portal provides access to high quality data and web-based applications created for the benefit of the global research community studying brain sciences.
*   [Human Connectome.org](https://www.humanconnectome.org) The human connectome houses and distributes public research data for a series of study  aspects of how age, growth, disease, and other factors can affect the ever-changing connections in the human brain.
*   [LORIS](http://loris.ca/) (Longitudinal Online Research and Imaging System) for heterogeneous data acquisition e.g. imaging, clinical, behavior, and genetics, storage, processing, and ultimately dissemination. [Read more](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3262165/).
*   [Child Mind Institute Healthy Brain Network](http://fcon_1000.projects.nitrc.org/indi/cmi_healthy_brain_network/), shares a biobank of data from 10,000 young participants. The HBN Biobank houses data about psychiatric, behavioral, cognitive, and lifestyle phenotypes, as well as multimodal brain imaging (fMRI, diffusion MRI, morphometric MRI), electroencephalography, eye-tracking, voice and video recordings, genetics and actigraphy [read more](https://www.nature.com/articles/sdata2017181).
*   The Alzheimer’s Disease Neuroimaging Initiative ([ADNI](http://adni.loni.usc.edu/)) collects, validate and utilises data, including MRI and PET images, genetics, cognitive tests, CSF and blood biomarkers as predictors of the disease.
*   [Brain Genomics Superstruct](http://neuroinformatics.harvard.edu/gsp/)
*   [Brain base](https://brainbase.io/) is a collaborative research and data management platform for the Human Neuroscience community.
*   NIH ABCD [Adolescent Brain Cognitive Development Study](https://addictionresearch.nih.gov/abcd-study)
*   [OASIS](http://www.oasis-brains.org/) The Open Access Series of Imaging Studies aims making neuroimaging data sets of the brain freely available to the scientific community. with > 1000 participants, over the course of 30 years, totalling 1500 raw imaging scans.
*   [Neurosynth](http://neurosynth.org/) is a platform for large-scale automated synthesis of fMRI data that allows meta-analysis.
*   [DaRIS](https://wiki.cloud.unimelb.edu.au/resplat/doku.php?id=data_management:daris:daris_features) (Distributed and Reflective Informatics System) is a framework for managing data and meta-data primarily for biomedical imaging.
*   [MyTardis](http://www.mytardis.org/) is an Australian solution that provides data transfer, manages data storage and provides mechanisms to access and share the data and it is domain agnostic.

### Microscopy

*   [Image Data Resource from Open Microscopy](https://idr.openmicroscopy.org/about/) (IDR) is a public data integration and publication platform.
*   [OMERO from Open Microscopy](https://www.openmicroscopy.org/omero/) is a central repository, OMERO supports over 140 image file formats, including all major microscope formats. It uses [bio-formats](http://www.openmicroscopy.org/bio-formats/).
*   [The Cell: An Image Library](http://www.cellimagelibrary.org/home) is a freely accessible, public repository of reviewed and annotated images, videos, and animations of cells from a variety of organisms, showcasing cell architecture, intracellular functionalities. It is registered in [identifiers.org](https://registry.identifiers.org/registry/cellimage).
*   [Electron microscopy Protein data bank](https://www.ebi.ac.uk/pdbe/emdb/).
*   [EMPIAR](https://www.ebi.ac.uk/pdbe/emdb/empiar/) (Electron Microscope Public Image Archive) for 2D images.

### Biomedical sciences
*   [UK Biobank](https://www.ukbiobank.ac.uk/) provides health information of over 500,000 volunteer participants de-identified, to approved researchers in the UK and overseas, from academia and industry.
*   The Cancer Imaging archive ([TCIA](https://www.cancerimagingarchive.net/)) is a service which de-identifies and hosts a large archive of medical images of cancer accessible for public download. The data are organized as “Collections”, typically patients related by a common disease, image modality (MRI, CT, etc) or research focus. DICOM is the primary file format used by TCIA for image storage.
*   [The Cardiac Atlas Project](https://www.cardiacatlas.org/) comprises cardiac imaging data from relevant studies such as MESA or DETERMINE.
*   [Siscas Medical imaging repository](https://www.smir.ch/) for CT and microCT images. It offers controlled access.
*   Coherent X-ray Imaging Data Bank ([CXIDB](http://www.cxidb.org/)) uses CXI file format.
*   [DeepLesion, a project from the NIH](https://nihcc.app.box.com/v/DeepLesion) that released a dataset of 32,000 CT chest images with different type of lesions.
*   Content manager [SciCrunch](https://scicrunch.org), a data sharing and display platform and training materials for searching and sharing in biomedical sciences across hundreds of databases.
*   [BioStudies](https://www.ebi.ac.uk/biostudies/) The database can accept a wide range of types of studies, and its used to describe it. It also enables manuscript authors to submit supplementary information and link to it from the publication.

### Non-domain specific
*   Australian Data Archive [ADA](https://ada.edu.au/) it has a Core Trust Seal Certification. It is mainly for digital data relating to social, political and economic affairs which might include social and health studies.
*   [Data dryad](https://datadryad.org).
*   [Dataverse.org](https://dataverse.org/)
*   [Zenodo.org](https://zenodo.org)

**Data registries and catalogues**
[re3data.org](https://www.re3data.org/) - a registry of some 2000 data repositories. [Research data australia](https://researchdata.ands.org.au) [read more](https://www.ands.org.au/online-services/research-data-australia).[FAIRSharing.org](https://fairsharing.org/standards/?q=imaging) offers a catalogue of databases, described according to the [BioDBcore guidelines](http://biocuration.org/community/standards-biodbcore/). [OpenAIRE content provider](https://provide.openaire.eu/landing), [European Open Science Cloud](https://catalogue.eosc-portal.eu/), [Google Public Data](https://www.google.com/publicdata/directory), [Google Dataset Share](https://toolbox.google.com/datasetsearch), for open access publications [Open knowledge maps](https://openknowledgemaps.org/).


# References
